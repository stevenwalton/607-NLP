\FloatBarrier
\section{Conclusion}

In this paper the authors perform experiments to answer when and where attention
is most useful in NLP problems. The paper found conclusive results at the
effectiveness of attention models and found that attention and feed-forward
layers were the most helpful. The experiments also showed that attention on the
encoding side is more important than the decoding side. 

